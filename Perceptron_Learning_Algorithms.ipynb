{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning memo\n",
    "\n",
    "最近剛上完台大林軒田老師的Machine Learning Techniques和Machine Learning Foundations，總時程大概一個多月，因為時間有一點長，所以這裡把自己train過的data整理一下，因為不像real world data一樣要花大部分的時間做preprocessing，都是可以直接拿來train的data，所以這邊只有整理一些演算法(算演算法嗎？)。\n",
    "\n",
    "### Perceptron Learning algorithm：\n",
    "\n",
    "先看一下PLA的基本核心：\n",
    "\n",
    "start from some $W_{0}$,\n",
    "\n",
    "For t = 0,1.......\n",
    "\n",
    "* find the next mistake of $W_{t}$ called ($X_{n(t)}$, $y_{n(t)}$):\n",
    "\n",
    "$$sign(W_{t}^{T}X_{n(t)}) \\neq y_{n(t)}$$\n",
    "\n",
    "* correct the mistake by:\n",
    "\n",
    "$$W_{t+1} \\leftarrow W_{t} + y_{n(t)} X_{n(t)} $$\n",
    "\n",
    "### 先load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_train15 = np.genfromtxt(\"/Users/huangyuchen/Desktop/ML_NTU/hw1_15_train.dat.txt\")\n",
    "X_train18 = np.genfromtxt(\"/Users/huangyuchen/Desktop/ML_NTU/hw1_18_train.dat.txt\")\n",
    "X_test18 = np.genfromtxt(\"/Users/huangyuchen/Desktop/ML_NTU/hw1_18_test.dat.txt\")\n",
    "## adding bias and initial W\n",
    "X_train15 = np.insert(X_train15,0,1,1)\n",
    "X_train18 = np.insert(X_train18,0,1,1)\n",
    "X_test18 = np.insert(X_test18,0,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def PLA(X,y):\n",
    "    error = 1\n",
    "    m,n = X.shape\n",
    "    W = np.zeros((1,n-1))\n",
    "    while (error!=0):\n",
    "        y = np.reshape(y,(m,1))\n",
    "        for i in range(m):\n",
    "            if np.sign(W.dot(X[i,:-1]))!= y[i]:\n",
    "                W = W + y[i]*X[i,:-1]                \n",
    "                error = min(error,np.mean(np.sign(X[:,:-1].dot(W.T))!=y))\n",
    "                break\n",
    "    \n",
    "    return error\n",
    "\n",
    "PLA(X_train15,X_train15[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由結果可以看到，因為是設計好的data的關係，所以PLA會停下來，並且得到$E_{in}=0$，然而這並不是一個實用的演算法，因為很明顯現實中的data並不是這麼的單純，為了解決這樣子的問題，有另一個類似的algorithms:Pocket algorithms。\n",
    "\n",
    "## Pocket Algorithms:\n",
    "\n",
    "先看一下Pocket Algorithms的基本核心：\n",
    "\n",
    "start from some $W_{0}$,\n",
    "\n",
    "For t = 0,1.......\n",
    "\n",
    "* find the (random) mistake of $W_{t}$ called ($X_{n(t)}$, $y_{n(t)}$):\n",
    "\n",
    "$$sign(W_{t}^{T}X_{n(t)}) \\neq y_{n(t)}$$\n",
    "\n",
    "* modify W by:\n",
    "\n",
    "$$W_{t+1} \\leftarrow W_{t} + y_{n(t)} X_{n(t)} $$\n",
    "\n",
    "如果$W_{t+1}$的結果比$W_{t}$好，就用$W_{t+1}$取代$W_{t}$，由於這次並沒有保證Pocket algorithms一定會停下來，所以停下來的決定是由我們相信足夠多次數的迭代決定的，這次就用X_train18來當做training samples。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.252"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Pocket(X,y,X_test,y_test,itera):\n",
    "    m,n = X.shape\n",
    "    o,p =X_test.shape\n",
    "    W = np.zeros((1,n-1))\n",
    "    y = np.reshape(y,(m,1))\n",
    "    y_test = np.reshape(y_test,(o,1))\n",
    "    l = 0\n",
    "    while l < itera:\n",
    "        np.random.shuffle(X)\n",
    "        error = np.mean(np.sign(X[:,:-1].dot(W.T))!=y)\n",
    "        if np.sign(W.dot(X[0,:-1]))!= y[0]:\n",
    "            W_ini = W + y[0]*X[0,:-1]                \n",
    "            error_new = np.mean(np.sign(X[:,:-1].dot(W_ini.T))!=y)\n",
    "            if error_new < error:\n",
    "                W = W_ini\n",
    "                continue\n",
    "        l+=1\n",
    "    return np.mean(np.sign(X_test[:,:-1].dot(W.T))!=y_test)\n",
    "\n",
    "Pocket(X_train18,X_train18[:,-1],X_test18,X_test18[:,-1],5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因為有shuffle training data的關係，所以$E_{out}$並不會每次都一樣，因此我們試著看看平均的$E_{out}$是多少。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.286\n"
     ]
    }
   ],
   "source": [
    "Eou = 0\n",
    "\n",
    "for i in range(100):\n",
    "    Eou+=Pocket(X_train18,X_train18[:,-1],X_test18,X_test18[:,-1],100) \n",
    "print(\"{:.3f}\".format(Eou/100))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
